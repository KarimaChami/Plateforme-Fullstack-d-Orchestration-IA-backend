# Plateforme-Fullstack-d-Orchestration-IA



# Backend

## ğŸ“‹ Description

Backend Python pour l'orchestration de services d'IA permettant la classification Zero-Shot (Hugging Face) et la synthÃ¨se contextuelle (Gemini API).

##  Architecture

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ user.py            # ModÃ¨les SQLAlchemy
â”‚   â”‚   â””â”€â”€ analyze.py   
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ auth.py            # Routes d'authentification
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gemini_client.py          
â”‚   â”‚   â””â”€â”€ hf_client.py   
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ config.py               # Configuration et variables d'environnement  
â”‚   â””â”€â”€ database.py           
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ gemi_test.py
â”‚   â””â”€â”€ hf_test.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ğŸš€ Installation

### PrÃ©requis

- Python 
- PostgreSQL 
- ClÃ©s API : Hugging Face & Google Gemini

### Ã‰tapes d'installation

1. **Cloner le projet**
```bash
git clone https://github.com/KarimaChami/Plateforme-Fullstack-d-Orchestration-IA-backend.git
cd ./backend
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
venv\Scripts\activate   
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement**
```bash
cp .env.example .env
```

5. **Initialiser la base de donnÃ©es**
```bash
python -m app.database init
```

6. **Lancer le serveur**
```bash
uvicorn app.main:app --reload 
```

## ğŸ“¡ API Endpoints

### Authentification

#### POST /register
CrÃ©er un nouveau compte utilisateur.

**Request:**
```json
{
  "username": "john_doe",
  "password": "SecureP@ssw0rd"
}
```

**Response:**
```json
{
  "message": "User created successfully",
  "user_id": 1
}
```

#### POST /login
Se connecter et obtenir un token JWT.

**Request:**
```json
{
  "username": "john_doe",
  "password": "SecureP@ssw0rd"
}
```

**Response:**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

### Analyse

#### POST /analyze
Analyser un texte (requiert authentification JWT).

**Headers:**
```
Authorization: Bearer <token>
```

**Request:**
```json
{
  "text": "Le marchÃ© boursier a connu une forte hausse aujourd'hui..."
}
```

**Response:**
```json
{
  "category": "Finance",
  "score": 0.92,
  "summary": "Analyse positive des marchÃ©s financiers montrant une tendance haussiÃ¨re avec des volumes d'Ã©changes Ã©levÃ©s.",
  "tone": "positif"
}
```

## ğŸ”§ Configuration des Services IA

### Hugging Face

Le service utilise le modÃ¨le `facebook/bart-large-mnli` pour la classification Zero-Shot.

**CatÃ©gories supportÃ©es:**
- Finance
- Ressources Humaines
- Technologies de l'Information
- OpÃ©rations
- Marketing
- Juridique
- Sales
- Legal
- Support
- Logistique


### Gemini

Prompt Engineering pour une synthÃ¨se contextualisÃ©e :

```python
prompt = f"""
Tu dois OBLIGATOIREMENT rÃ©pondre en JSON strict.
Aucun texte hors du JSON.
MÃªme si le texte est court, donne un rÃ©sumÃ© et un ton.

RÃ©pond EXACTEMENT comme ceci :

{{
    "summary": "...",
    "tone": "positif" 
}}

Texte : {text}
"""
```

## ğŸ§ª Tests

### Lancer tous les tests
```bash
pytest
```

### Tests spÃ©cifiques
```bash
pytest tests/hf_test.py -v
pytest tests/gemi_test.py -v
```

### Structure des tests

- **hf_test.py** : Tests de l'intÃ©gration HF
- **gemi_test.py** : Tests de l'intÃ©gration Gemini

## ğŸ“Š Logs

Les logs sont configurÃ©s dans `app/utils/logger.py` et incluent :

- **INFO** : RequÃªtes API, orchestration des services
- **WARNING** : Scores de classification faibles, timeouts
- **ERROR** : Erreurs critiques, Ã©checs d'API
- **DEBUG** : DÃ©tails techniques (mode dÃ©veloppement uniquement)


## ğŸ”’ SÃ©curitÃ©

### JWT
- Token signÃ© avec HS256
- Expiration configurable (dÃ©faut: 30 minutes)
- Validation sur tous les endpoints protÃ©gÃ©s

### Passwords
- Hashage avec argon2
- Validation de la complexitÃ© minimale
- Jamais stockÃ©s en clair

### API Keys
- StockÃ©es dans variables d'environnement
- Jamais commitÃ©es dans le code
- Rotation rÃ©guliÃ¨re recommandÃ©e

## ğŸ³ Docker

### Build de l'image
```bash
docker build -t backend .
```

### Lancer avec Docker Compose
```bash
docker-compose up -d
```

## ğŸ› ï¸ DÃ©pendances principales

```
fastapi==0.104.1
uvicorn==0.24.0
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
pydantic==2.5.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
requests==2.31.0
python-dotenv==1.0.0
google-generativeai==0.3.1
pytest==7.4.3
pytest-cov==4.1.0
```

## ğŸš¨ Gestion des erreurs

### Erreurs courantes

| Code | Description | Solution |
|------|-------------|----------|
| 401 | Non autorisÃ© | VÃ©rifier le token JWT |
| 422 | Validation Ã©chouÃ©e | VÃ©rifier le format de la requÃªte |
| 500 | Erreur serveur | Consulter les logs |
| 503 | Service indisponible | API externe down (HF/Gemini) |


## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request


## ğŸ‘¥ Auteurs

- Karima Chami - DÃ©vloppeuse Fullstack & Ai

## ğŸ”— Liens utiles

- [Documentation Hugging Face Inference API](https://huggingface.co/docs/api-inference/index)
- [Documentation Gemini API](https://ai.google.dev/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)